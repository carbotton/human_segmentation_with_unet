{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bloque básico de U-Net++:\n",
    "    Conv -> BN (opcional) -> ReLU -> Conv -> BN (opcional) -> ReLU\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, use_bn=True, dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=not use_bn)\n",
    "        ]\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm2d(out_ch))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        if dropout > 0.0:\n",
    "          layers.append(nn.Dropout2d(dropout))\n",
    "\n",
    "        layers.append(\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=not use_bn)\n",
    "        )\n",
    "        if use_bn:\n",
    "            layers.append(nn.BatchNorm2d(out_ch))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        if dropout > 0.0:\n",
    "          layers.append(nn.Dropout2d(dropout))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net++ (Nested U-Net) para segmentación 2D.\n",
    "\n",
    "    - n_channels: canales de entrada (3 para RGB)\n",
    "    - n_classes: canales de salida (1 para segmentación binaria)\n",
    "    - deep_supervision: si True, devuelve promedio de varias salidas intermedias\n",
    "    - use_bn: usa BatchNorm en los ConvBlocks\n",
    "    - base_ch: número de filtros en el primer nivel (por defecto 64)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels: int = 3,\n",
    "        n_classes: int = 1,\n",
    "        deep_supervision: bool = False,\n",
    "        use_bn: bool = True,\n",
    "        base_ch: int = 64,\n",
    "        dropout=0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        # Canales en cada nivel del encoder\n",
    "        nb_filter = [\n",
    "            base_ch,\n",
    "            base_ch * 2,\n",
    "            base_ch * 4,\n",
    "            base_ch * 8,\n",
    "            base_ch * 16,\n",
    "        ]\n",
    "\n",
    "        # ---------------- ENCODER (X_{i,0}) ----------------\n",
    "        self.conv0_0 = ConvBlock(n_channels, nb_filter[0], use_bn, dropout)\n",
    "        self.conv1_0 = ConvBlock(nb_filter[0], nb_filter[1], use_bn, dropout)\n",
    "        self.conv2_0 = ConvBlock(nb_filter[1], nb_filter[2], use_bn, dropout)\n",
    "        self.conv3_0 = ConvBlock(nb_filter[2], nb_filter[3], use_bn, dropout)\n",
    "        self.conv4_0 = ConvBlock(nb_filter[3], nb_filter[4], use_bn, dropout)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # -------------- BLOQUES NESTED (decoder) -----------\n",
    "        # X_{0,1}, X_{1,1}, X_{2,1}, X_{3,1}\n",
    "        self.conv0_1 = ConvBlock(nb_filter[0] + nb_filter[1], nb_filter[0], use_bn, dropout)\n",
    "        self.conv1_1 = ConvBlock(nb_filter[1] + nb_filter[2], nb_filter[1], use_bn, dropout)\n",
    "        self.conv2_1 = ConvBlock(nb_filter[2] + nb_filter[3], nb_filter[2], use_bn, dropout)\n",
    "        self.conv3_1 = ConvBlock(nb_filter[3] + nb_filter[4], nb_filter[3], use_bn, dropout)\n",
    "\n",
    "        # X_{0,2}, X_{1,2}, X_{2,2}\n",
    "        self.conv0_2 = ConvBlock(nb_filter[0] * 2 + nb_filter[1], nb_filter[0], use_bn, dropout)\n",
    "        self.conv1_2 = ConvBlock(nb_filter[1] * 2 + nb_filter[2], nb_filter[1], use_bn, dropout)\n",
    "        self.conv2_2 = ConvBlock(nb_filter[2] * 2 + nb_filter[3], nb_filter[2], use_bn, dropout)\n",
    "\n",
    "        # X_{0,3}, X_{1,3}\n",
    "        self.conv0_3 = ConvBlock(nb_filter[0] * 3 + nb_filter[1], nb_filter[0], use_bn, dropout)\n",
    "        self.conv1_3 = ConvBlock(nb_filter[1] * 3 + nb_filter[2], nb_filter[1], use_bn, dropout)\n",
    "\n",
    "        # X_{0,4}\n",
    "        self.conv0_4 = ConvBlock(nb_filter[0] * 4 + nb_filter[1], nb_filter[0], use_bn, dropout)\n",
    "\n",
    "        # Upsample (siempre x2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Convs de salida para deep supervision\n",
    "        if self.deep_supervision:\n",
    "            self.final1 = nn.Conv2d(nb_filter[0], n_classes, kernel_size=1)\n",
    "            self.final2 = nn.Conv2d(nb_filter[0], n_classes, kernel_size=1)\n",
    "            self.final3 = nn.Conv2d(nb_filter[0], n_classes, kernel_size=1)\n",
    "            self.final4 = nn.Conv2d(nb_filter[0], n_classes, kernel_size=1)\n",
    "        else:\n",
    "            self.final = nn.Conv2d(nb_filter[0], n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ---------------- ENCODER ----------------\n",
    "        x0_0 = self.conv0_0(x)              # (B, f0, H,   W)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))# (B, f1, H/2, W/2)\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))# (B, f2, H/4, W/4)\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))# (B, f3, H/8, W/8)\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))# (B, f4, H/16,W/16)\n",
    "\n",
    "        # ---------------- DECODER NESTED ----------------\n",
    "        # Nivel j = 1\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], dim=1))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], dim=1))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], dim=1))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], dim=1))\n",
    "\n",
    "        # Nivel j = 2\n",
    "        x0_2 = self.conv0_2(\n",
    "            torch.cat([x0_0, x0_1, self.up(x1_1)], dim=1)\n",
    "        )\n",
    "        x1_2 = self.conv1_2(\n",
    "            torch.cat([x1_0, x1_1, self.up(x2_1)], dim=1)\n",
    "        )\n",
    "        x2_2 = self.conv2_2(\n",
    "            torch.cat([x2_0, x2_1, self.up(x3_1)], dim=1)\n",
    "        )\n",
    "\n",
    "        # Nivel j = 3\n",
    "        x0_3 = self.conv0_3(\n",
    "            torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], dim=1)\n",
    "        )\n",
    "        x1_3 = self.conv1_3(\n",
    "            torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], dim=1)\n",
    "        )\n",
    "\n",
    "        # Nivel j = 4\n",
    "        x0_4 = self.conv0_4(\n",
    "            torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], dim=1)\n",
    "        )\n",
    "\n",
    "        # ---------------- SALIDAS ----------------\n",
    "        if self.deep_supervision:\n",
    "            output1 = self.final1(x0_1)\n",
    "            output2 = self.final2(x0_2)\n",
    "            output3 = self.final3(x0_3)\n",
    "            output4 = self.final4(x0_4)\n",
    "            # Podés devolver la lista o el promedio\n",
    "            return (output1 + output2 + output3 + output4) / 4.0\n",
    "        else:\n",
    "            logits = self.final(x0_4)\n",
    "            return logits   # (B, n_classes, H, W) logits (sin sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1b1de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_unet_plus_drop, val_loader_unet_plus_drop, test_loader_unet_plus_drop, kaggle_loader_unet_plus_drop = get_seg_dataloaders(\n",
    "    \"data/train\",\n",
    "    batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, seed=SEED, rgb=True,\n",
    "    train_transform_img=base_img_tf,\n",
    "    train_transform_mask=base_mask_tf,\n",
    "    val_transform_img=base_img_tf,\n",
    "    val_transform_mask=base_mask_tf,  \n",
    ")\n",
    "\n",
    "unet_plus_drop = UNetPlusPlus(\n",
    "    n_channels=3,\n",
    "    n_classes=1,\n",
    "    deep_supervision=False,   # o True si querés experimentar\n",
    "    use_bn=True,\n",
    "    base_ch=64,\n",
    "    dropout=0.3\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = combined_loss  # por ejemplo BCE + Dice o Focal Tversky\n",
    "optimizer_unet_plus_drop = torch.optim.Adam(unet_plus_drop.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler_unet_plus_drop = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_unet_plus_drop, mode=\"min\", factor=0.5, patience=4)\n",
    "\n",
    "# unet_plus_drop, _, checkpoint = restaurar_modelo(unet_plus_drop, None, \"models/unet_plus_plus_2.pth\", DEVICE)\n",
    "\n",
    "\n",
    "epoch_train_errors_unet_plus_drop, epoch_val_errors_unet_plus_drop = train(\n",
    "    unet_plus_drop, optimizer_unet_plus_drop, criterion, train_loader_unet_plus_drop, val_loader_unet_plus_drop, DEVICE, scheduler=scheduler_unet_plus_drop,\n",
    "    do_early_stopping=True, patience=15, epochs=80, log_every=5,\n",
    "    checkpoint_path=\"models/unet_plus_drop_3.pth\", \n",
    "    loss_ponderada=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
